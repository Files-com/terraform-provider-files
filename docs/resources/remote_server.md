---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "files_remote_server Resource - files"
subcategory: ""
description: |-
  A RemoteServer is a specific type of Behavior called remote_server_sync.
  Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.
  Not every attribute will apply to every remote server.
  FTP Servers require that you specify their hostname, port, username, password, and a value for ssl. Optionally, provide server_certificate.
  SFTP Servers require that you specify their hostname, port, username, password or private_key, and a value for ssl. Optionally, provide server_certificate, private_key_passphrase.
  S3 Buckets require that you specify their s3_bucket name, and s3_region. Optionally provide a aws_access_key, and aws_secret_key. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.
  S3-Compatible Buckets require that you specify s3_compatible_bucket, s3_compatible_endpoint, s3_compatible_access_key, and s3_compatible_secret_key.
  Google Cloud Storage requires that you specify google_cloud_storage_bucket, and then one of the following sets of authentication credentials:
  
  for JSON authentcation: google_cloud_storage_project_id, and google_cloud_storage_credentials_json
  for HMAC (S3-Compatible) authentication: google_cloud_storage_s3_compatible_access_key, and google_cloud_storage_s3_compatible_secret_key
  Wasabi requires wasabi_bucket, wasabi_region, wasabi_access_key, and wasabi_secret_key.
  Backblaze B2 Cloud Storage backblaze_b2_bucket, backblaze_b2_s3_endpoint, backblaze_b2_application_key, and backblaze_b2_key_id. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453
  WebDAV Servers require that you specify their hostname, username, and password.
  OneDrive follow the auth_setup_link and login with Microsoft.
  Sharepoint follow the auth_setup_link and login with Microsoft.
  Box follow the auth_setup_link and login with Box.
  Dropbox specify if dropbox_teams then follow the auth_setup_link and login with Dropbox.
  Google Drive follow the auth_setup_link and login with Google.
  Azure Blob Storage azure_blob_storage_account, azure_blob_storage_container, azure_blob_storage_access_key, azure_blob_storage_sas_token, azure_blob_storage_dns_suffix
  Azure File Storage azure_files_storage_account, azure_files_storage_access_key, azure_files_storage_share_name, azure_files_storage_dns_suffix
  Filebase requires filebase_bucket, filebase_access_key, and filebase_secret_key.
  Cloudflare requires cloudflare_bucket, cloudflare_access_key, cloudflare_secret_key and cloudflare_endpoint.
  Linode requires linode_bucket, linode_access_key, linode_secret_key and linode_region.
---

# files_remote_server (Resource)

A RemoteServer is a specific type of Behavior called `remote_server_sync`.



Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.



Not every attribute will apply to every remote server.



FTP Servers require that you specify their `hostname`, `port`, `username`, `password`, and a value for `ssl`. Optionally, provide `server_certificate`.



SFTP Servers require that you specify their `hostname`, `port`, `username`, `password` or `private_key`, and a value for `ssl`. Optionally, provide `server_certificate`, `private_key_passphrase`.



S3 Buckets require that you specify their `s3_bucket` name, and `s3_region`. Optionally provide a `aws_access_key`, and `aws_secret_key`. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.



S3-Compatible Buckets require that you specify `s3_compatible_bucket`, `s3_compatible_endpoint`, `s3_compatible_access_key`, and `s3_compatible_secret_key`.



Google Cloud Storage requires that you specify `google_cloud_storage_bucket`, and then one of the following sets of authentication credentials:

 - for JSON authentcation: `google_cloud_storage_project_id`, and `google_cloud_storage_credentials_json`

 - for HMAC (S3-Compatible) authentication: `google_cloud_storage_s3_compatible_access_key`, and `google_cloud_storage_s3_compatible_secret_key`



Wasabi requires `wasabi_bucket`, `wasabi_region`, `wasabi_access_key`, and `wasabi_secret_key`.



Backblaze B2 Cloud Storage `backblaze_b2_bucket`, `backblaze_b2_s3_endpoint`, `backblaze_b2_application_key`, and `backblaze_b2_key_id`. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453



WebDAV Servers require that you specify their `hostname`, `username`, and `password`.



OneDrive follow the `auth_setup_link` and login with Microsoft.



Sharepoint follow the `auth_setup_link` and login with Microsoft.



Box follow the `auth_setup_link` and login with Box.



Dropbox specify if `dropbox_teams` then follow the `auth_setup_link` and login with Dropbox.



Google Drive follow the `auth_setup_link` and login with Google.



Azure Blob Storage `azure_blob_storage_account`, `azure_blob_storage_container`, `azure_blob_storage_access_key`, `azure_blob_storage_sas_token`, `azure_blob_storage_dns_suffix`



Azure File Storage `azure_files_storage_account`, `azure_files_storage_access_key`, `azure_files_storage_share_name`, `azure_files_storage_dns_suffix`



Filebase requires `filebase_bucket`, `filebase_access_key`, and `filebase_secret_key`.



Cloudflare requires `cloudflare_bucket`, `cloudflare_access_key`, `cloudflare_secret_key` and `cloudflare_endpoint`.



Linode requires `linode_bucket`, `linode_access_key`, `linode_secret_key` and `linode_region`.

## Example Usage

```terraform
resource "files_remote_server" "example_remote_server" {
  reset_authentication                          = false
  aws_access_key                                = "example"
  azure_blob_storage_account                    = "storage-account-name"
  azure_blob_storage_container                  = "container-name"
  azure_blob_storage_dns_suffix                 = "usgovcloudapi.net"
  azure_blob_storage_hierarchical_namespace     = true
  azure_files_storage_account                   = "storage-account-name"
  azure_files_storage_dns_suffix                = "file.core.windows.net"
  azure_files_storage_share_name                = "share-name"
  backblaze_b2_bucket                           = "my-bucket"
  backblaze_b2_s3_endpoint                      = "s3.us-west-001.backblazeb2.com"
  buffer_uploads                                = "example"
  cloudflare_access_key                         = "example"
  cloudflare_bucket                             = "my-bucket"
  cloudflare_endpoint                           = "https://<ACCOUNT_ID>.r2.cloudflarestorage.com"
  description                                   = "More information or notes about my server"
  dropbox_teams                                 = true
  enable_dedicated_ips                          = true
  filebase_access_key                           = "example"
  filebase_bucket                               = "my-bucket"
  files_agent_permission_set                    = "read_write"
  files_agent_root                              = "example"
  files_agent_version                           = "example"
  outbound_agent_id                             = 1
  google_cloud_storage_bucket                   = "my-bucket"
  google_cloud_storage_project_id               = "my-project"
  google_cloud_storage_s3_compatible_access_key = "example"
  hostname                                      = "remote-server.com"
  linode_access_key                             = "example"
  linode_bucket                                 = "my-bucket"
  linode_region                                 = "us-east-1"
  max_connections                               = 1
  name                                          = "My Remote server"
  one_drive_account_type                        = "personal"
  pin_to_site_region                            = true
  port                                          = 1
  remote_server_credential_id                   = 1
  s3_bucket                                     = "my-bucket"
  s3_compatible_access_key                      = "example"
  s3_compatible_bucket                          = "my-bucket"
  s3_compatible_endpoint                        = "mys3platform.com"
  s3_compatible_region                          = "us-east-1"
  s3_region                                     = "us-east-1"
  server_certificate                            = "require_match"
  server_host_key                               = "[public key]"
  server_type                                   = "s3"
  ssl                                           = "if_available"
  username                                      = "user"
  wasabi_access_key                             = "example"
  wasabi_bucket                                 = "my-bucket"
  wasabi_region                                 = "us-west-1"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Optional

> **NOTE**: [Write-only arguments](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments) are supported in Terraform 1.11 and later.

- `aws_access_key` (String) AWS Access Key.
- `aws_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) AWS: secret key.
- `azure_blob_storage_access_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Azure Blob Storage: Access Key
- `azure_blob_storage_account` (String) Azure Blob Storage: Account name
- `azure_blob_storage_container` (String) Azure Blob Storage: Container name
- `azure_blob_storage_dns_suffix` (String) Azure Blob Storage: Custom DNS suffix
- `azure_blob_storage_hierarchical_namespace` (Boolean) Azure Blob Storage: Does the storage account has hierarchical namespace feature enabled?
- `azure_blob_storage_sas_token` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Azure Blob Storage: Shared Access Signature (SAS) token
- `azure_files_storage_access_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Azure File Storage: Access Key
- `azure_files_storage_account` (String) Azure Files: Storage Account name
- `azure_files_storage_dns_suffix` (String) Azure Files: Custom DNS suffix
- `azure_files_storage_sas_token` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Azure File Storage: Shared Access Signature (SAS) token
- `azure_files_storage_share_name` (String) Azure Files:  Storage Share name
- `backblaze_b2_application_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Backblaze B2 Cloud Storage: applicationKey
- `backblaze_b2_bucket` (String) Backblaze B2 Cloud Storage: Bucket name
- `backblaze_b2_key_id` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Backblaze B2 Cloud Storage: keyID
- `backblaze_b2_s3_endpoint` (String) Backblaze B2 Cloud Storage: S3 Endpoint
- `buffer_uploads` (String) If set to always, uploads to this server will be uploaded first to Files.com before being sent to the remote server. This can improve performance in certain access patterns, such as high-latency connections.  It will cause data to be temporarily stored in Files.com. If set to auto, we will perform this optimization if we believe it to be a benefit in a given situation.
- `cloudflare_access_key` (String) Cloudflare: Access Key.
- `cloudflare_bucket` (String) Cloudflare: Bucket name
- `cloudflare_endpoint` (String) Cloudflare: endpoint
- `cloudflare_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Cloudflare: Secret Key
- `description` (String) Internal description for your reference
- `dropbox_teams` (Boolean) Dropbox: If true, list Team folders in root?
- `enable_dedicated_ips` (Boolean) `true` if remote server only accepts connections from dedicated IPs
- `filebase_access_key` (String) Filebase: Access Key.
- `filebase_bucket` (String) Filebase: Bucket name
- `filebase_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Filebase: Secret Key
- `files_agent_permission_set` (String) Local permissions for files agent. read_only, write_only, or read_write
- `files_agent_root` (String) Agent local root path
- `files_agent_version` (String) Files Agent version
- `google_cloud_storage_bucket` (String) Google Cloud Storage: Bucket Name
- `google_cloud_storage_credentials_json` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Google Cloud Storage: JSON file that contains the private key. To generate see https://cloud.google.com/storage/docs/json_api/v1/how-tos/authorizing#APIKey
- `google_cloud_storage_project_id` (String) Google Cloud Storage: Project ID
- `google_cloud_storage_s3_compatible_access_key` (String) Google Cloud Storage: S3-compatible Access Key.
- `google_cloud_storage_s3_compatible_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Google Cloud Storage: S3-compatible secret key
- `hostname` (String) Hostname or IP address
- `linode_access_key` (String) Linode: Access Key
- `linode_bucket` (String) Linode: Bucket name
- `linode_region` (String) Linode: region
- `linode_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Linode: Secret Key
- `max_connections` (Number) Max number of parallel connections.  Ignored for S3 connections (we will parallelize these as much as possible).
- `name` (String) Internal name for your reference
- `one_drive_account_type` (String) OneDrive: Either personal or business_other account types
- `outbound_agent_id` (Number) Route traffic to outbound on a files-agent
- `password` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Password, if needed.
- `pin_to_site_region` (Boolean) If true, we will ensure that all communications with this remote server are made through the primary region of the site.  This setting can also be overridden by a site-wide setting which will force it to true.
- `port` (Number) Port for remote server.
- `private_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Private key, if needed.
- `private_key_passphrase` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Passphrase for private key if needed.
- `remote_server_credential_id` (Number) ID of Remote Server Credential, if applicable.
- `reset_authentication` (Boolean, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Reset authenticated account?
- `s3_bucket` (String) S3 bucket name
- `s3_compatible_access_key` (String) S3-compatible: Access Key
- `s3_compatible_bucket` (String) S3-compatible: Bucket name
- `s3_compatible_endpoint` (String) S3-compatible: endpoint
- `s3_compatible_region` (String) S3-compatible: region
- `s3_compatible_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) S3-compatible: Secret Key
- `s3_region` (String) S3 region
- `server_certificate` (String) Remote server certificate
- `server_host_key` (String) Remote server SSH Host Key. If provided, we will require that the server host key matches the provided key. Uses OpenSSH format similar to what would go into ~/.ssh/known_hosts
- `server_type` (String) Remote server type.
- `ssl` (String) Should we require SSL?
- `ssl_certificate` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) SSL client certificate.
- `username` (String) Remote server username.
- `wasabi_access_key` (String) Wasabi: Access Key.
- `wasabi_bucket` (String) Wasabi: Bucket name
- `wasabi_region` (String) Wasabi: Region
- `wasabi_secret_key` (String, [Write-only](https://developer.hashicorp.com/terraform/language/resources/ephemeral#write-only-arguments)) Wasabi: Secret Key

### Read-Only

- `auth_account_name` (String) Describes the authorized account
- `auth_status` (String) Either `in_setup` or `complete`
- `authentication_method` (String) Type of authentication method
- `disabled` (Boolean) If true, this server has been disabled due to failures.  Make any change or set disabled to false to clear this flag.
- `files_agent_api_token` (String) Files Agent API Token
- `id` (Number) Remote server ID
- `pinned_region` (String) If set, all communications with this remote server are made through the provided region.
- `remote_home_path` (String) Initial home folder on remote server
- `supports_versioning` (Boolean) If true, this remote server supports file versioning. This value is determined automatically by Files.com.

## Import

Import is supported using the following syntax:

```shell
# Remote Servers can be imported by specifying the id.
terraform import files_remote_server.example_remote_server 1
```
