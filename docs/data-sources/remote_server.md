---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "files_remote_server Data Source - files"
subcategory: ""
description: |-
  A RemoteServer is a specific type of Behavior called remote_server_sync.
  Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.
  Not every attribute will apply to every remote server.
  FTP Servers require that you specify their hostname, port, username, password, and a value for ssl. Optionally, provide server_certificate.
  SFTP Servers require that you specify their hostname, port, username, password or private_key, and a value for ssl. Optionally, provide server_certificate, private_key_passphrase.
  S3 Buckets require that you specify their s3_bucket name, and s3_region. Optionally provide a aws_access_key, and aws_secret_key. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.
  S3-Compatible Buckets require that you specify s3_compatible_bucket, s3_compatible_endpoint, s3_compatible_access_key, and s3_compatible_secret_key.
  Google Cloud Storage requires that you specify google_cloud_storage_bucket, and then one of the following sets of authentication credentials:
  
  for JSON authentcation: google_cloud_storage_project_id, and google_cloud_storage_credentials_json
  for HMAC (S3-Compatible) authentication: google_cloud_storage_s3_compatible_access_key, and google_cloud_storage_s3_compatible_secret_key
  Wasabi requires wasabi_bucket, wasabi_region, wasabi_access_key, and wasabi_secret_key.
  Backblaze B2 Cloud Storage backblaze_b2_bucket, backblaze_b2_s3_endpoint, backblaze_b2_application_key, and backblaze_b2_key_id. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453
  WebDAV Servers require that you specify their hostname, username, and password.
  OneDrive follow the auth_setup_link and login with Microsoft.
  Sharepoint follow the auth_setup_link and login with Microsoft.
  Box follow the auth_setup_link and login with Box.
  Dropbox specify if dropbox_teams then follow the auth_setup_link and login with Dropbox.
  Google Drive follow the auth_setup_link and login with Google.
  Azure Blob Storage azure_blob_storage_account, azure_blob_storage_container, azure_blob_storage_access_key, azure_blob_storage_sas_token, azure_blob_storage_dns_suffix
  Azure File Storage azure_files_storage_account, azure_files_storage_access_key, azure_files_storage_share_name, azure_files_storage_dns_suffix
  Filebase requires filebase_bucket, filebase_access_key, and filebase_secret_key.
  Cloudflare requires cloudflare_bucket, cloudflare_access_key, cloudflare_secret_key and cloudflare_endpoint.
  Linode requires linode_bucket, linode_access_key, linode_secret_key and linode_region.
---

# files_remote_server (Data Source)

A RemoteServer is a specific type of Behavior called `remote_server_sync`.



Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.



Not every attribute will apply to every remote server.



FTP Servers require that you specify their `hostname`, `port`, `username`, `password`, and a value for `ssl`. Optionally, provide `server_certificate`.



SFTP Servers require that you specify their `hostname`, `port`, `username`, `password` or `private_key`, and a value for `ssl`. Optionally, provide `server_certificate`, `private_key_passphrase`.



S3 Buckets require that you specify their `s3_bucket` name, and `s3_region`. Optionally provide a `aws_access_key`, and `aws_secret_key`. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.



S3-Compatible Buckets require that you specify `s3_compatible_bucket`, `s3_compatible_endpoint`, `s3_compatible_access_key`, and `s3_compatible_secret_key`.



Google Cloud Storage requires that you specify `google_cloud_storage_bucket`, and then one of the following sets of authentication credentials:

 - for JSON authentcation: `google_cloud_storage_project_id`, and `google_cloud_storage_credentials_json`

 - for HMAC (S3-Compatible) authentication: `google_cloud_storage_s3_compatible_access_key`, and `google_cloud_storage_s3_compatible_secret_key`



Wasabi requires `wasabi_bucket`, `wasabi_region`, `wasabi_access_key`, and `wasabi_secret_key`.



Backblaze B2 Cloud Storage `backblaze_b2_bucket`, `backblaze_b2_s3_endpoint`, `backblaze_b2_application_key`, and `backblaze_b2_key_id`. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453



WebDAV Servers require that you specify their `hostname`, `username`, and `password`.



OneDrive follow the `auth_setup_link` and login with Microsoft.



Sharepoint follow the `auth_setup_link` and login with Microsoft.



Box follow the `auth_setup_link` and login with Box.



Dropbox specify if `dropbox_teams` then follow the `auth_setup_link` and login with Dropbox.



Google Drive follow the `auth_setup_link` and login with Google.



Azure Blob Storage `azure_blob_storage_account`, `azure_blob_storage_container`, `azure_blob_storage_access_key`, `azure_blob_storage_sas_token`, `azure_blob_storage_dns_suffix`



Azure File Storage `azure_files_storage_account`, `azure_files_storage_access_key`, `azure_files_storage_share_name`, `azure_files_storage_dns_suffix`



Filebase requires `filebase_bucket`, `filebase_access_key`, and `filebase_secret_key`.



Cloudflare requires `cloudflare_bucket`, `cloudflare_access_key`, `cloudflare_secret_key` and `cloudflare_endpoint`.



Linode requires `linode_bucket`, `linode_access_key`, `linode_secret_key` and `linode_region`.

## Example Usage

```terraform
data "files_remote_server" "example_remote_server" {
  id = 1
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `id` (Number) Remote Server ID

### Read-Only

- `allow_relative_paths` (Boolean) Allow relative paths in SFTP. If true, paths will not be forced to be absolute, allowing operations relative to the user's home directory.
- `auth_account_name` (String) Describes the authorized account
- `auth_status` (String) Either `in_setup` or `complete`
- `authentication_method` (String) Type of authentication method to use
- `aws_access_key` (String) AWS Access Key.
- `azure_blob_storage_account` (String) Azure Blob Storage: Account name
- `azure_blob_storage_container` (String) Azure Blob Storage: Container name
- `azure_blob_storage_dns_suffix` (String) Azure Blob Storage: Custom DNS suffix
- `azure_blob_storage_hierarchical_namespace` (Boolean) Azure Blob Storage: Does the storage account has hierarchical namespace feature enabled?
- `azure_files_storage_account` (String) Azure Files: Storage Account name
- `azure_files_storage_dns_suffix` (String) Azure Files: Custom DNS suffix
- `azure_files_storage_share_name` (String) Azure Files:  Storage Share name
- `backblaze_b2_bucket` (String) Backblaze B2 Cloud Storage: Bucket name
- `backblaze_b2_s3_endpoint` (String) Backblaze B2 Cloud Storage: S3 Endpoint
- `buffer_uploads` (String) If set to always, uploads to this server will be uploaded first to Files.com before being sent to the remote server. This can improve performance in certain access patterns, such as high-latency connections.  It will cause data to be temporarily stored in Files.com. If set to auto, we will perform this optimization if we believe it to be a benefit in a given situation.
- `cloudflare_access_key` (String) Cloudflare: Access Key.
- `cloudflare_bucket` (String) Cloudflare: Bucket name
- `cloudflare_endpoint` (String) Cloudflare: endpoint
- `description` (String) Internal description for your reference
- `disabled` (Boolean) If true, this Remote Server has been disabled due to failures.  Make any change or set disabled to false to clear this flag.
- `dropbox_teams` (Boolean) Dropbox: If true, list Team folders in root?
- `enable_dedicated_ips` (Boolean) `true` if remote server only accepts connections from dedicated IPs
- `filebase_access_key` (String) Filebase: Access Key.
- `filebase_bucket` (String) Filebase: Bucket name
- `files_agent_api_token` (String) Files Agent API Token
- `files_agent_latest_version` (String) Latest available Files Agent version
- `files_agent_permission_set` (String) Local permissions for files agent. read_only, write_only, or read_write
- `files_agent_root` (String) Agent local root path
- `files_agent_supports_push_updates` (Boolean) Files Agent supports receiving push updates
- `files_agent_up_to_date` (Boolean) If true, the Files Agent is up to date.
- `files_agent_version` (String) Files Agent version
- `google_cloud_storage_bucket` (String) Google Cloud Storage: Bucket Name
- `google_cloud_storage_project_id` (String) Google Cloud Storage: Project ID
- `google_cloud_storage_s3_compatible_access_key` (String) Google Cloud Storage: S3-compatible Access Key.
- `hostname` (String) Hostname or IP address
- `linode_access_key` (String) Linode: Access Key
- `linode_bucket` (String) Linode: Bucket name
- `linode_region` (String) Linode: region
- `max_connections` (Number) Max number of parallel connections.  Ignored for S3 connections (we will parallelize these as much as possible).
- `name` (String) Internal name for your reference
- `one_drive_account_type` (String) OneDrive: Either personal or business_other account types
- `outbound_agent_id` (Number) Route traffic to outbound on a files-agent
- `pin_to_site_region` (Boolean) If true, we will ensure that all communications with this remote server are made through the primary region of the site.  This setting can also be overridden by a site-wide setting which will force it to true.
- `pinned_region` (String) If set, all communications with this remote server are made through the provided region.
- `port` (Number) Port for remote server.
- `remote_home_path` (String) Initial home folder on remote server
- `remote_server_credential_id` (Number) ID of Remote Server Credential, if applicable.
- `s3_bucket` (String) S3 bucket name
- `s3_compatible_access_key` (String) S3-compatible: Access Key
- `s3_compatible_bucket` (String) S3-compatible: Bucket name
- `s3_compatible_endpoint` (String) S3-compatible: endpoint
- `s3_compatible_region` (String) S3-compatible: region
- `s3_region` (String) S3 region
- `server_certificate` (String) Remote server certificate
- `server_host_key` (String) Remote server SSH Host Key. If provided, we will require that the server host key matches the provided key. Uses OpenSSH format similar to what would go into ~/.ssh/known_hosts
- `server_type` (String) Remote server type.
- `ssl` (String) Should we require SSL?
- `supports_versioning` (Boolean) If true, this remote server supports file versioning. This value is determined automatically by Files.com.
- `upload_staging_path` (String) Upload staging path.  Applies to SFTP only.  If a path is provided here, files will first be uploaded to this path on the remote folder and the moved into the final correct path via an SFTP move command.  This is required by some remote MFT systems to emulate atomic uploads, which are otherwise not supoprted by SFTP.
- `username` (String) Remote server username.
- `wasabi_access_key` (String) Wasabi: Access Key.
- `wasabi_bucket` (String) Wasabi: Bucket name
- `wasabi_region` (String) Wasabi: Region
- `workspace_id` (Number) Workspace ID (0 for default workspace)
