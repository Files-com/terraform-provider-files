---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "files_remote_server Data Source - files"
subcategory: ""
description: |-
  Remote servers are used with the remote_server_sync Behavior.
  Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.
  Not every attribute will apply to every remote server.
  FTP Servers require that you specify their hostname, port, username, password, and a value for ssl. Optionally, provide server_certificate.
  SFTP Servers require that you specify their hostname, port, username, password or private_key, and a value for ssl. Optionally, provide server_certificate, private_key_passphrase.
  S3 Buckets require that you specify their s3_bucket name, and s3_region. Optionally provide a aws_access_key, and aws_secret_key. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.
  S3-Compatible Buckets require that you specify s3_compatible_bucket, s3_compatible_endpoint, s3_compatible_access_key, and s3_compatible_secret_key.
  Google Cloud Storage requires that you specify google_cloud_storage_bucket, google_cloud_storage_project_id, and google_cloud_storage_credentials_json.
  Wasabi requires wasabi_bucket, wasabi_region, wasabi_access_key, and wasabi_secret_key.
  Backblaze B2 Cloud Storage backblaze_b2_bucket, backblaze_b2_s3_endpoint, backblaze_b2_application_key, and backblaze_b2_key_id. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453
  Rackspace Cloud Files requires rackspace_username, rackspace_api_key, rackspace_region, and rackspace_container.
  WebDAV Servers require that you specify their hostname, username, and password.
  OneDrive follow the auth_setup_link and login with Microsoft.
  Sharepoint follow the auth_setup_link and login with Microsoft.
  Box follow the auth_setup_link and login with Box.
  Dropbox specify if dropbox_teams then follow the auth_setup_link and login with Dropbox.
  Google Drive follow the auth_setup_link and login with Google.
  Azure Blob Storage azure_blob_storage_account, azure_blob_storage_container, azure_blob_storage_access_key, azure_blob_storage_sas_token
  Azure File Storage azure_files_storage_account, azure_files_storage_access_key, azure_files_storage_share_name
  Filebase requires filebase_bucket, filebase_access_key, and filebase_secret_key.
  Cloudflare requires cloudflare_bucket, cloudflare_access_key, cloudflare_secret_key and cloudflare_endpoint.
  Linode requires linode_bucket, linode_access_key, linode_secret_key and linode_region.
---

# files_remote_server (Data Source)

Remote servers are used with the `remote_server_sync` Behavior.



Remote Servers can be either an FTP server, SFTP server, S3 bucket, Google Cloud Storage, Wasabi, Backblaze B2 Cloud Storage, Rackspace Cloud Files container, WebDAV, Box, Dropbox, OneDrive, Google Drive, or Azure Blob Storage.



Not every attribute will apply to every remote server.



FTP Servers require that you specify their `hostname`, `port`, `username`, `password`, and a value for `ssl`. Optionally, provide `server_certificate`.



SFTP Servers require that you specify their `hostname`, `port`, `username`, `password` or `private_key`, and a value for `ssl`. Optionally, provide `server_certificate`, `private_key_passphrase`.



S3 Buckets require that you specify their `s3_bucket` name, and `s3_region`. Optionally provide a `aws_access_key`, and `aws_secret_key`. If you don't provide credentials, you will need to use AWS to grant us access to your bucket.



S3-Compatible Buckets require that you specify `s3_compatible_bucket`, `s3_compatible_endpoint`, `s3_compatible_access_key`, and `s3_compatible_secret_key`.



Google Cloud Storage requires that you specify `google_cloud_storage_bucket`, `google_cloud_storage_project_id`, and `google_cloud_storage_credentials_json`.



Wasabi requires `wasabi_bucket`, `wasabi_region`, `wasabi_access_key`, and `wasabi_secret_key`.



Backblaze B2 Cloud Storage `backblaze_b2_bucket`, `backblaze_b2_s3_endpoint`, `backblaze_b2_application_key`, and `backblaze_b2_key_id`. (Requires S3 Compatible API) See https://help.backblaze.com/hc/en-us/articles/360047425453



Rackspace Cloud Files requires `rackspace_username`, `rackspace_api_key`, `rackspace_region`, and `rackspace_container`.



WebDAV Servers require that you specify their `hostname`, `username`, and `password`.



OneDrive follow the `auth_setup_link` and login with Microsoft.



Sharepoint follow the `auth_setup_link` and login with Microsoft.



Box follow the `auth_setup_link` and login with Box.



Dropbox specify if `dropbox_teams` then follow the `auth_setup_link` and login with Dropbox.



Google Drive follow the `auth_setup_link` and login with Google.



Azure Blob Storage `azure_blob_storage_account`, `azure_blob_storage_container`, `azure_blob_storage_access_key`, `azure_blob_storage_sas_token`



Azure File Storage `azure_files_storage_account`, `azure_files_storage_access_key`, `azure_files_storage_share_name`



Filebase requires `filebase_bucket`, `filebase_access_key`, and `filebase_secret_key`.



Cloudflare requires `cloudflare_bucket`, `cloudflare_access_key`, `cloudflare_secret_key` and `cloudflare_endpoint`.



Linode requires `linode_bucket`, `linode_access_key`, `linode_secret_key` and `linode_region`.

## Example Usage

```terraform
data "files_remote_server" "example_remote_server" {
  id = 1
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `id` (Number) Remote server ID

### Read-Only

- `auth_account_name` (String) Describes the authorized account
- `auth_setup_link` (String) Returns link to login with an Oauth provider
- `auth_status` (String) Either `in_setup` or `complete`
- `authentication_method` (String) Type of authentication method
- `aws_access_key` (String) AWS Access Key.
- `azure_blob_storage_account` (String) Azure Blob Storage Account name
- `azure_blob_storage_container` (String) Azure Blob Storage Container name
- `azure_blob_storage_hierarchical_namespace` (Boolean) Enable when storage account has hierarchical namespace feature enabled
- `azure_files_storage_account` (String) Azure File Storage Account name
- `azure_files_storage_share_name` (String) Azure File Storage Share name
- `backblaze_b2_bucket` (String) Backblaze B2 Cloud Storage Bucket name
- `backblaze_b2_s3_endpoint` (String) Backblaze B2 Cloud Storage S3 Endpoint
- `cloudflare_access_key` (String) Cloudflare Access Key.
- `cloudflare_bucket` (String) Cloudflare Bucket name
- `cloudflare_endpoint` (String) Cloudflare endpoint
- `disabled` (Boolean) If true, this server has been disabled due to failures.  Make any change or set disabled to false to clear this flag.
- `dropbox_teams` (Boolean) List Team folders in root
- `enable_dedicated_ips` (Boolean) `true` if remote server only accepts connections from dedicated IPs
- `filebase_access_key` (String) Filebase Access Key.
- `filebase_bucket` (String) Filebase Bucket name
- `files_agent_api_token` (String) Files Agent API Token
- `files_agent_permission_set` (String) Local permissions for files agent. read_only, write_only, or read_write
- `files_agent_root` (String) Agent local root path
- `files_agent_version` (String) Files Agent version
- `google_cloud_storage_bucket` (String) Google Cloud Storage bucket name
- `google_cloud_storage_project_id` (String) Google Cloud Project ID
- `hostname` (String) Hostname or IP address
- `linode_access_key` (String) Linode Access Key.
- `linode_bucket` (String) Linode Bucket name
- `linode_region` (String) Linode region
- `max_connections` (Number) Max number of parallel connections.  Ignored for S3 connections (we will parallelize these as much as possible).
- `name` (String) Internal name for your reference
- `one_drive_account_type` (String) Either personal or business_other account types
- `pin_to_site_region` (Boolean) If true, we will ensure that all communications with this remote server are made through the primary region of the site.  This setting can also be overridden by a sitewide setting which will force it to true.
- `pinned_region` (String) If set, all communciations with this remote server are made through the provided region.
- `port` (Number) Port for remote server.  Not needed for S3.
- `rackspace_container` (String) The name of the container (top level directory) where files will sync.
- `rackspace_region` (String) Three letter airport code for Rackspace region. See https://support.rackspace.com/how-to/about-regions/
- `rackspace_username` (String) Rackspace username used to login to the Rackspace Cloud Control Panel.
- `remote_home_path` (String) Initial home folder on remote server
- `s3_bucket` (String) S3 bucket name
- `s3_compatible_access_key` (String) S3-compatible Access Key.
- `s3_compatible_bucket` (String) S3-compatible Bucket name
- `s3_compatible_endpoint` (String) S3-compatible endpoint
- `s3_compatible_region` (String) S3-compatible endpoint
- `s3_region` (String) S3 region
- `server_certificate` (String) Remote server certificate
- `server_host_key` (String) Remote server SSH Host Key. If provided, we will require that the server host key matches the provided key. Uses OpenSSH format similar to what would go into ~/.ssh/known_hosts
- `server_type` (String) Remote server type.
- `ssl` (String) Should we require SSL?
- `supports_versioning` (Boolean) If true, this remote server supports file versioning. This value is determined automatically by Files.com.
- `username` (String) Remote server username.  Not needed for S3 buckets.
- `wasabi_access_key` (String) Wasabi access key.
- `wasabi_bucket` (String) Wasabi Bucket name
- `wasabi_region` (String) Wasabi region
